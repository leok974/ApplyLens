# Production Stack for ApplyLens
# Full production-ready deployment with all services
#
# Usage:
#   1. Copy infra/.env.example to infra/.env and configure production values
#   2. docker-compose -f docker-compose.prod.yml up -d
#   3. Run migrations: docker-compose -f docker-compose.prod.yml exec api alembic upgrade head
#
# Services:
#   - PostgreSQL 16 (database)
#   - Elasticsearch 8.13 (search & analytics)
#   - Kibana 8.13 (data visualization)
#   - FastAPI (backend API)
#   - React/Vite (frontend)
#   - Nginx (reverse proxy)
#   - Prometheus (metrics) - LEGACY: Datadog is now primary observability
#   - Grafana (monitoring) - LEGACY: Datadog is now primary observability
#   - Cloudflared (tunnel - optional)
#
# NOTE: Prometheus/Grafana are marked as LEGACY (as of Nov 2025).
# Datadog is now the primary observability provider.
# These services are retained temporarily for:
#   - Historical metrics data
#   - Transition period monitoring
#   - Safe decommissioning later (Phase 3)
# See: hackathon/DATADOG_SETUP.md for current observability setup

services:
  # =============================================================================
  # DATABASE
  # =============================================================================
  db:
    image: postgres:16-alpine
    container_name: applylens-db-prod
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB:-applylens}
      POSTGRES_INITDB_ARGS: "-E UTF8 --locale=en_US.UTF-8"
    # Ports not exposed in production (internal network only)
    # ports:
    #   - "5432:5432"
    volumes:
      - db_data_prod:/var/lib/postgresql/data
      - ./infra/postgres/init:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres} -d ${POSTGRES_DB:-applylens}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - applylens-prod

  # =============================================================================
  # ELASTICSEARCH
  # =============================================================================
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.4
    container_name: applylens-es-prod
    environment:
      - node.name=es-prod
      - cluster.name=applylens-cluster
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    # Ports not exposed in production (internal network only)
    # ports:
    #   - "9200:9200"
    volumes:
      - es_data_prod:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    networks:
      - applylens-prod

  # =============================================================================
  # KIBANA
  # =============================================================================
  kibana:
    image: docker.elastic.co/kibana/kibana:8.13.4
    container_name: applylens-kibana-prod
    environment:
      - ELASTICSEARCH_HOSTS=http://es:9200
      - SERVER_NAME=applylens-kibana
      - SERVER_HOST=0.0.0.0
    ports:
      - "5601:5601"
    volumes:
      - ./infra/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml:ro
      - kibana_data_prod:/usr/share/kibana/data
    depends_on:
      elasticsearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5601/kibana/api/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    networks:
      - applylens-prod

  # =============================================================================
  # REDIS (Caching)
  # =============================================================================
  redis:
    image: redis:7-alpine
    container_name: applylens-redis-prod
    command: redis-server --appendonly yes
    # Ports not exposed in production (internal network only)
    # ports:
    #   - "6379:6379"
    volumes:
      - redis_data_prod:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    restart: unless-stopped
    networks:
      - applylens-prod

  # =============================================================================
  # OLLAMA (Local LLM Service)
  # PRODUCTION NOTE: Using existing infra-ollama-1 container via external infra_net
  # DO NOT add a new ollama service here - we share the infra container
  # =============================================================================

  # =============================================================================
  # API (FastAPI Backend)
  # =============================================================================
  api:
    build:
      context: ./services/api
      dockerfile: Dockerfile.prod
    # v0.4.47: Phase 1.5 - Conversational suggestions (intent-aware next_steps + followup_prompt)
    # v0.4.44: Phase 1.5 Enhancements - sender_email field + tone parameter for draft regeneration
    # v0.4.42: Phase 1.5 - Auto-draft follow-up replies (POST /assistant/draft-reply closes the loop: Inbox → Tracker → Reply)
    # v0.4.41: Phase 1.4 - LLM integration (Ollama → OpenAI fallback for intent classification + summary polishing)
    # v0.4.40: Phase 1.2 & 1.3 - Bulk action execution + sender memory (real unsubscribe/quarantine/mute)
    # v0.4.39: Mailbox Assistant with real ES queries (Phase 1.1 - live data from gmail_emails index)
    # v0.4.38: Added Mailbox Assistant /api/assistant/query endpoint with structured responses
    # v0.4.36: Added APP_VERSION to settings, /config endpoint returns version for UI
    # v0.4.35: /tracker endpoint returns demo data, /applications marked as internal/legacy
    # v0.4.34: Fixed /applications router prefix alignment with nginx
    # v0.4.33: Postgres sender overrides migration + API changes
    # v0.4.32: Settings page for sender overrides + adaptive classification + insights panel
    # v0.4.31: Actionability fix - loosened review filter (unread OR risk >= 40)
    # v0.4.30: Status chips + Restore to Review (undo actions)
    # v0.4.29: Inbox Actions lifecycle with Needs Review / Quarantined / Archived views
    # v0.4.48: Phase 3 - Hybrid LLM provider (Ollama→OpenAI→fallback) + short-term memory context hints
    # v0.4.47: Mailbox Assistant with conversational suggestions (next_steps + followup_prompt)
    # v0.4.42: Auto-draft follow-up replies endpoint - /api/assistant/draft-reply
    # v0.4.40: Sender overrides (safe/mute) for adaptive classification
    # v0.4.33: Runtime config endpoint + basic tracker endpoint
    # v0.4.30: Status chips + Restore to Review (undo actions)
    # v0.4.29: Inbox Actions lifecycle with Needs Review / Quarantined / Archived views
    # v0.4.28: Polished interactive triage console with optimistic UI updates
    # v0.4.27: Enhanced Actions page with drawer, explanations, and optimistic UI updates
    # v0.4.26: Implemented Actions page with real backend endpoints
    # v0.4.25: Added /api/tracker endpoint for Gmail-derived applications
    # v0.5.8: Intent override - explicit intent for toolbar buttons Agent V2 Learning Loop - feedback routes + aggregation endpoint
    # v0.4.49: Profile warehouse integration + Ollama production deployment
    # v0.5.8: Intent override - explicit intent for toolbar buttons Banana Pro theme visual polish - warm yellow SaaS cockpit design
    # v0.5.8: Intent override - explicit intent for toolbar buttons Card merging - prevent LLM from nuking thread_list cards
    # v0.5.9: Count fix - meta.count in summary cards (was incorrectly at top level)
    # Card-aware answering - LLM references card metadata, no hallucinated company names
    # Zero-results phrasing - Don't say "card below" when count=0
    # v0.5.1: Application tracking integration - Thread Viewer with tracker linkage
    # v0.6.0: Today Panel - Inbox triage with 6 scan intents, thread mini-lists, responsive grid UI
    # v0.6.1: Thread Viewer follow-up draft feature (POST /v2/agent/followup-draft)
    # v0.6.2: Follow-up Queue - unified view merging mailbox followups + Tracker applications
    # v0.6.3: Persistent follow-up state with progress tracking and done/not-done toggles
    # v0.6.4: Today panel Follow-ups summary widget with progress and quick navigation
    # v0.6.5-datadog: Datadog automation scripts for dashboard, SLOs, and monitors
    # v0.7.5: Remove FollowupQueueRequest dependency to fix 422 validation error
    # v0.7.4: Fix followup-queue authentication with current_user dependency
    # v0.7.2: Follow-up queue GET support + deep-link warning cleanup
    image: leoklemet/applylens-api:0.7.5
    container_name: applylens-api-prod
    environment:
      # Database
      DATABASE_URL: "postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-4c9248fc7d7d477d919ccc431b1bbd36!PgA1}@db:5432/${POSTGRES_DB:-applylens}"
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-4c9248fc7d7d477d919ccc431b1bbd36!PgA1}
      POSTGRES_DB: ${POSTGRES_DB:-applylens}

      # API Configuration
      ENV: production
      API_HOST: 0.0.0.0
      API_PORT: ${API_PORT:-8003}
      CORS_ALLOW_ORIGINS: ${CORS_ALLOW_ORIGINS:-http://localhost:5175,http://localhost:3000}

      # Elasticsearch
      ES_ENABLED: ${ES_ENABLED:-true}
      ES_URL: http://es:9200
      ES_RECREATE_ON_START: "false"
      ELASTICSEARCH_INDEX: ${ELASTICSEARCH_INDEX:-gmail_emails}

      # Redis (Caching)
      REDIS_URL: redis://redis:6379/0

      # LLM Integration (Phase 3 - Production Ollama)
      # CRITICAL: Using shared infra-ollama-1 container on infra_net network
      # DO NOT change to http://localhost:11434 - must use container hostname
      # DO NOT change model back to gpt-oss:20b - too slow for production
      OLLAMA_BASE: "http://ai-finance-agent-oss-clean-ollama-1:11434"
      OLLAMA_MODEL: "gpt-oss:20b"  # 4.7GB, 2-4s response time (quoted for YAML colon handling)
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      OPENAI_MODEL: ${OPENAI_MODEL:-gpt-4o-mini}

      # Assistant Configuration
      ASSISTANT_INTERNAL_API_BASE: http://api:8003

      # Google OAuth (credentials read from google.json file, not env vars)
      GOOGLE_CREDENTIALS: ${GOOGLE_CREDENTIALS:-/secrets/google.json}
      GOOGLE_CLIENT_ID: ${GOOGLE_CLIENT_ID}
      GOOGLE_CLIENT_SECRET: ${GOOGLE_CLIENT_SECRET}
      OAUTH_REDIRECT_URI: ${OAUTH_REDIRECT_URI:-http://localhost:8003/auth/google/callback}
      GOOGLE_OAUTH_SCOPES: ${GOOGLE_OAUTH_SCOPES:-https://www.googleapis.com/auth/gmail.readonly https://www.googleapis.com/auth/userinfo.email openid}
      OAUTH_STATE_SECRET: ${OAUTH_STATE_SECRET}

      # Google OAuth for routers/auth.py (requires APPLYLENS_ prefix)
      APPLYLENS_GOOGLE_CLIENT_ID: ${GOOGLE_CLIENT_ID}
      APPLYLENS_GOOGLE_CLIENT_SECRET: ${GOOGLE_CLIENT_SECRET}
      APPLYLENS_OAUTH_REDIRECT_URI: ${OAUTH_REDIRECT_URI:-http://localhost:8003/auth/google/callback}

      # Application
      DEFAULT_USER_EMAIL: ${DEFAULT_USER_EMAIL}

      # Build Metadata
      APP_VERSION: '0.7.5'
      APP_BUILD_SHA: '411e0e0'
      APP_BUILD_TIME: '2025-11-28T22:30:00Z'
      APP_ENV: 'production'
      CREATE_TABLES_ON_STARTUP: "0"

      # Feature Flags
      ALLOW_DEV_ROUTES: "0"  # Production: Disable dev routes
      CHAT_STREAMING_ENABLED: ${CHAT_STREAMING_ENABLED:-true}  # Canary toggle for SSE streaming
      ALLOW_ACTION_MUTATIONS: "true"  # v0.4.29: Enable mutations for lifecycle management

      # Security - Token Encryption (Added 2025-10-20)
      APPLYLENS_AES_KEY_BASE64: ${APPLYLENS_AES_KEY_BASE64}

      # Security - CSRF Protection
      CSRF_SECRET_KEY: ${CSRF_SECRET_KEY}

      # E2E Testing
      E2E_PROD: "1"
      E2E_SHARED_SECRET: "e2e-prod-5a46844ddc9f4cb2"
      SHARED_SECRET: ${SHARED_SECRET}

      # Security - reCAPTCHA (optional)
      RECAPTCHA_ENABLED: ${RECAPTCHA_ENABLED:-false}
      RECAPTCHA_SITE_KEY: ${RECAPTCHA_SITE_KEY:-}
      RECAPTCHA_SECRET_KEY: ${RECAPTCHA_SECRET_KEY:-}
      RECAPTCHA_MIN_SCORE: ${RECAPTCHA_MIN_SCORE:-0.5}

      # Fivetran & BigQuery Warehouse
      USE_WAREHOUSE_METRICS: ${USE_WAREHOUSE_METRICS:-0}
      GCP_PROJECT: ${GCP_PROJECT}
      BQ_MARTS_DATASET: ${BQ_MARTS_DATASET:-gmail_marts}
      GOOGLE_APPLICATION_CREDENTIALS: ${GOOGLE_APPLICATION_CREDENTIALS:-/app/secrets/applylens-warehouse-key.json}

      # Gmail Backfill API Key
      BACKFILL_API_KEY: ${BACKFILL_API_KEY:-}

      # Monitoring
      PROMETHEUS_ENABLED: "true"
      PROMETHEUS_URL: http://prometheus:9090
      LOG_LEVEL: ${LOG_LEVEL:-info}
    ports:
      - "${API_PORT:-8003}:8003"
    volumes:
      - ./infra/secrets:/secrets:ro
      - ./secrets:/app/secrets:ro
      - api_logs_prod:/var/log/applylens
    depends_on:
      db:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request; urllib.request.urlopen('http://localhost:8003/ready')\" || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    networks:
      applylens-prod:
        aliases:
          - applylens-api.internal
      infra_net:  # Connect to infra network for Ollama access
      shared-ollama:  # Connect to shared Ollama container

  # =============================================================================
  # BACKFILL SCHEDULER (Automated Gmail Backfill)
  # =============================================================================
  backfill:
    image: python:3.11-slim
    container_name: applylens-backfill
    restart: unless-stopped
    networks:
      - applylens-prod
    environment:
      # Internal call to API (no Cloudflare)
      API_URL: http://applylens-api-prod:8003/gmail/backfill
      BACKFILL_API_KEY: ${BACKFILL_API_KEY:-}
      EVERY_MINUTES: ${BACKFILL_EVERY_MINUTES:-30}
      BACKFILL_DAYS: ${BACKFILL_DAYS:-2}
      TZ: America/New_York
    volumes:
      - ./infra/backfill:/app:ro
    working_dir: /app
    command: ["python", "/app/runner.py"]
    depends_on:
      api:
        condition: service_healthy
    labels:
      - "com.applylens.role=backfill"
    healthcheck:
      test: ["CMD", "python", "/app/healthcheck.py"]
      interval: 5m
      timeout: 15s
      retries: 1
      start_period: 90s

  # =============================================================================
  # AUTOFILL AGGREGATOR (Companion Learning Loop)
  # =============================================================================
  autofill-aggregator:
    image: python:3.11-slim
    container_name: applylens-autofill-aggregator
    restart: unless-stopped
    networks:
      - applylens-prod
    environment:
      # Database connection (same as API)
      DATABASE_URL: postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB:-applylens}

      # Feature flag and configuration
      COMPANION_AUTOFILL_AGG_ENABLED:
      AGG_EVERY_HOURS:
      AGG_LOOKBACK_DAYS:
      TZ: America/New_York

      # Python path for imports
      PYTHONPATH: /api
    volumes:
      - ./infra/autofill-aggregator:/app:ro
      - ./services/api:/api:ro
    working_dir: /app
    command: ["python", "/app/runner.py"]
    depends_on:
      db:
        condition: service_healthy
      api:
        condition: service_healthy
    labels:
      - "com.applylens.role=autofill-aggregator"
    healthcheck:
      test: ["CMD", "python", "/app/healthcheck.py"]
      interval: 10m
      timeout: 30s
      retries: 2
      start_period: 120s

  # =============================================================================
  # AGENT FEEDBACK AGGREGATOR (Learning Loop)
  # =============================================================================
  agent-feedback-cron:
    image: python:3.11-slim
    container_name: applylens-agent-feedback-cron
    restart: unless-stopped
    networks:
      - applylens-prod
    environment:
      # Internal call to API (no Cloudflare, no /api prefix for internal calls)
      API_URL: http://applylens-api-prod:8003/v2/agent/feedback/aggregate
      BACKFILL_API_KEY: ${BACKFILL_API_KEY:-}
      EVERY_HOURS: ${AGENT_FEEDBACK_EVERY_HOURS:-6}
      TIMEOUT: ${AGENT_FEEDBACK_TIMEOUT:-120}
      TZ: America/New_York
    volumes:
      - ./infra/agent-feedback-cron:/app:ro
    working_dir: /app
    command: >
      sh -c "pip install --quiet -r /app/requirements.txt && python /app/runner.py"
    depends_on:
      api:
        condition: service_healthy
    labels:
      - "com.applylens.role=agent-feedback-cron"
    healthcheck:
      test: ["CMD", "python", "/app/healthcheck.py"]
      interval: 1h
      timeout: 15s
      retries: 2
      start_period: 90s

  # =============================================================================
  # WEB (Frontend)
  # =============================================================================
  web:
    # v0.7.3: Fix followup-queue API path (/api/v2/agent/followup-queue)
    # v0.7.2: Follow-up queue GET support + deep-link warning cleanup
    # v0.7.1: Fixed literal \n text showing on Today page
    # v0.7.0: Simplified header with theme in user dropdown
    #   - Removed sync buttons from header (now in Settings page)
    #   - Removed standalone theme toggle from header
    #   - Added theme submenu to user dropdown (Light/Dark/System)
    #   - Added Profile and Settings links to dropdown
    #   - Settings page now has Gmail Sync and Appearance cards
    #   - useTheme hook supports system theme with media query listener
    # v0.6.9: Full-width header with distributed nav links
    #   - Container changed to w-full max-w-7xl for more breathing room
    #   - Nav uses justify-between to distribute links across space
    #   - gap-4 for airier spacing between nav items
    #   - First link hugs logo, last link hugs profile, rest evenly distributed
    image: leoklemet/applylens-web:0.7.3
    container_name: applylens-web-prod
    environment:
      - NODE_ENV=production

      # Build Metadata (Web)
      - VITE_BUILD_FLAVOR=prod
      - VITE_APP_VERSION=0.7.3
      - VITE_BUILD_GIT_SHA=1da2d9f
      - VITE_BUILD_TIME=2025-11-28T21:45:00Z

      # Feature Flags
      - VITE_FEATURE_COMPANION=1
      - VITE_CHAT_AGENT_V2=1
    ports:
      - "${WEB_PORT:-5175}:80"
    depends_on:
      - api
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:80/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    restart: unless-stopped
    networks:
      - applylens-prod

  # =============================================================================
  # PROMETHEUS (Metrics Collection) - LEGACY
  # =============================================================================
  # NOTE: Prometheus/Grafana marked legacy (Datadog is primary observability).
  # Retained temporarily for historical charts & safe decommissioning later.
  # See: hackathon/DATADOG_SETUP.md for Datadog configuration.
  prometheus:
    image: prom/prometheus:v2.55.1
    container_name: applylens-prometheus-prod
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--storage.tsdb.retention.time=30d'
    ports:
      - "9090:9090"
    volumes:
      - ./infra/prometheus:/etc/prometheus:ro
      - prometheus_data_prod:/prometheus
    depends_on:
      - api
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:9090/-/healthy || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - applylens-prod

  # =============================================================================
  # GRAFANA (Monitoring Dashboard) - LEGACY
  # =============================================================================
  # NOTE: Prometheus/Grafana marked legacy (Datadog is primary observability).
  # Retained temporarily for historical charts & safe decommissioning later.
  # See: hackathon/DATADOG_SETUP.md for Datadog configuration.
  grafana:
    image: grafana/grafana:11.1.0
    container_name: applylens-grafana-prod
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_INSTALL_PLUGINS=grafana-piechart-panel,marcusolsson-json-datasource
      - GF_SERVER_ROOT_URL=${GRAFANA_ROOT_URL:-http://localhost:3000}
      - GF_ANALYTICS_REPORTING_ENABLED=false
      - GF_ANALYTICS_CHECK_FOR_UPDATES=false
      - GF_USERS_ALLOW_SIGN_UP=false
    ports:
      - "3000:3000"
    volumes:
      - ./infra/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./infra/grafana/grafana.ini:/etc/grafana/grafana.ini:ro
      - ./infra/grafana/dashboards:/var/lib/grafana/dashboards:ro
      - grafana_data_prod:/var/lib/grafana
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - applylens-prod

  # =============================================================================
  # NGINX (Reverse Proxy)
  # =============================================================================
  nginx:
    image: nginx:1.27-alpine
    container_name: applylens-nginx-prod
    ports:
      - "80:80"
      - "443:443"
    volumes:
      # Only mount production nginx config
      - ./infra/nginx/conf.d/applylens.prod.conf:/etc/nginx/conf.d/default.conf:ro
      - ./infra/nginx/snippets:/etc/nginx/snippets:ro
      - ./infra/nginx/ssl:/etc/nginx/ssl:ro
      - nginx_logs_prod:/var/log/nginx
    depends_on:
      - api
      - web
      - grafana
      - kibana
      - prometheus
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      applylens-prod:
        aliases:
          - applylens.internal
          - applylens.int

  # =============================================================================
  # CLOUDFLARED (Optional - Cloudflare Tunnel)
  # =============================================================================
  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: applylens-cloudflared-prod
    command: tunnel --no-autoupdate run --token ${CLOUDFLARED_TUNNEL_TOKEN}
    depends_on:
      - nginx
    restart: unless-stopped
    networks:
      - applylens-prod

# =============================================================================
# VOLUMES
# =============================================================================
volumes:
  db_data_prod:
    driver: local
  es_data_prod:
    driver: local
  kibana_data_prod:
    driver: local
  redis_data_prod:
    driver: local
  prometheus_data_prod:
    driver: local
  grafana_data_prod:
    driver: local
  api_logs_prod:
    driver: local
  nginx_logs_prod:
    driver: local

# =============================================================================
# NETWORKS
# =============================================================================
networks:
  applylens-prod:
    driver: bridge
    ipam:
      config:
        - subnet: 172.25.0.0/16
  infra_net:
    external: true  # Use existing infra network with Ollama
  shared-ollama:
    external: true  # Shared Ollama network (ai-finance-agent-oss-clean-ollama-1)
