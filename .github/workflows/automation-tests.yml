name: Automation Tests

on:
  workflow_dispatch:
    inputs:
      sample_size:
        description: 'Parity check sample size'
        default: '1000'
        type: string
      allow_mismatches:
        description: 'Max allowed mismatches'
        default: '0'
        type: string
  pull_request:
    paths:
      - 'services/api/**'
      - '.github/workflows/automation-tests.yml'
  push:
    branches:
      - main
    paths:
      - 'services/api/**'

jobs:
  # ===================================================================
  # UNIT TESTS
  # ===================================================================
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: applylens
        ports:
          - 5433:5432
        options: >-
          --health-cmd="pg_isready -U postgres -d applylens"
          --health-interval=3s
          --health-timeout=3s
          --health-retries=20
    
    env:
      DATABASE_URL: postgresql://postgres:postgres@localhost:5433/applylens
      ENV: test
      CREATE_TABLES_ON_STARTUP: "0"
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        working-directory: services/api
        run: |
          pip install -e .[test]
      
      - name: Run Alembic migrations
        working-directory: services/api
        run: |
          alembic upgrade head
      
      - name: Run unit tests
        working-directory: services/api
        run: |
          pytest -m unit \
            --cov=app \
            --cov-report=term-missing \
            --cov-report=html \
            --cov-report=lcov \
            --junit-xml=pytest-report.xml \
            -v
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          files: services/api/coverage.lcov
          flags: unit-tests
          fail_ci_if_error: false
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: unit-test-results
          path: |
            services/api/pytest-report.xml
            services/api/htmlcov/
      
      - name: Check coverage threshold
        working-directory: services/api
        run: |
          # Extract coverage percentage and check >= 90%
          coverage report | tail -1 | awk '{print $NF}' | sed 's/%//' | \
          awk '{if ($1 < 90) exit 1}'

  # ===================================================================
  # API TESTS
  # ===================================================================
  api-tests:
    name: API Contract Tests
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: applylens
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        ports:
          - 5433:5432
        options: >-
          --health-cmd="pg_isready -U postgres -d applylens"
          --health-interval=3s
          --health-timeout=3s
          --health-retries=20
      
      elasticsearch:
        image: docker.elastic.co/elasticsearch/elasticsearch:8.12.0
        env:
          discovery.type: single-node
          xpack.security.enabled: false
          ES_JAVA_OPTS: -Xms512m -Xmx512m
        ports:
          - 9200:9200
        options: >-
          --health-cmd "curl -f http://localhost:9200/_cluster/health || exit 1"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10
    
    env:
      DATABASE_URL: postgresql://postgres:postgres@localhost:5433/applylens
      ELASTICSEARCH_URL: http://localhost:9200
      ES_INDEX: test_emails
      ENV: test
      CREATE_TABLES_ON_STARTUP: "0"
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        working-directory: services/api
        run: |
          pip install -e .[test]
      
      - name: Run database migrations
        working-directory: services/api
        run: |
          alembic upgrade head
      
      - name: Start API server
        working-directory: services/api
        run: |
          uvicorn app.main:app --host 0.0.0.0 --port 8003 &
          echo $! > api.pid
          sleep 10
      
      - name: Wait for API to be ready
        run: |
          timeout 60 bash -c 'until curl -f http://localhost:8003/metrics; do sleep 2; done'
      
      - name: Run API tests
        working-directory: services/api
        env:
          API_BASE_URL: http://localhost:8003
        run: |
          pytest -m api \
            --junit-xml=api-test-results.xml \
            -v
      
      - name: Upload API test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: api-test-results
          path: services/api/api-test-results.xml
      
      - name: Stop API server
        if: always()
        working-directory: services/api
        run: |
          if [ -f api.pid ]; then
            kill $(cat api.pid) || true
          fi

  # ===================================================================
  # PARITY CHECK
  # ===================================================================
  parity-check:
    name: DB-ES Parity Check
    runs-on: ubuntu-latest
    needs: [unit-tests]  # Only run if unit tests pass
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: applylens_test
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      
      elasticsearch:
        image: docker.elastic.co/elasticsearch/elasticsearch:8.12.0
        env:
          discovery.type: single-node
          xpack.security.enabled: false
          ES_JAVA_OPTS: -Xms512m -Xmx512m
        ports:
          - 9200:9200
        options: >-
          --health-cmd "curl -f http://localhost:9200/_cluster/health || exit 1"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        working-directory: services/api
        run: |
          pip install -e .
      
      - name: Run database migrations
        working-directory: services/api
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/applylens_test
        run: |
          alembic upgrade head
      
      - name: Seed test data
        working-directory: services/api
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/applylens_test
          ELASTICSEARCH_URL: http://localhost:9200
          ES_INDEX: test_emails
        run: |
          # Run risk scoring to populate data
          python scripts/analyze_risk.py || true
      
      - name: Run parity check
        id: parity
        continue-on-error: true
        working-directory: services/api
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/applylens_test
          ELASTICSEARCH_URL: http://localhost:9200
          ES_INDEX: test_emails
          SAMPLE: ${{ github.event.inputs.sample_size || '100' }}
          ALLOW: ${{ github.event.inputs.allow_mismatches || (github.ref == 'refs/heads/main' && '0' || '3') }}
        run: |
          python scripts/check_parity.py \
            --fields risk_score,expires_at,category \
            --sample $SAMPLE \
            --output parity.json \
            --csv parity.csv \
            --allow $ALLOW
      
      - name: Upload parity results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: parity-check-results
          path: |
            services/api/parity.json
            services/api/parity.csv
      
      - name: Parse parity report
        if: always()
        id: parse_report
        working-directory: services/api
        run: |
          if [ -f parity.json ]; then
            total=$(jq '.summary.total_checked' parity.json)
            mismatches=$(jq '.summary.total_mismatches' parity.json)
            percentage=$(jq '.summary.mismatch_percentage' parity.json)
            
            echo "total=$total" >> $GITHUB_OUTPUT
            echo "mismatches=$mismatches" >> $GITHUB_OUTPUT
            echo "percentage=$percentage" >> $GITHUB_OUTPUT
            
            # Create summary
            echo "### Parity Check Results" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| Total Checked | $total |" >> $GITHUB_STEP_SUMMARY
            echo "| Mismatches | $mismatches |" >> $GITHUB_STEP_SUMMARY
            echo "| Mismatch % | $percentage% |" >> $GITHUB_STEP_SUMMARY
            
            # Field breakdown
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "#### By Field:" >> $GITHUB_STEP_SUMMARY
            jq -r '.summary.by_field | to_entries[] | "- \(.key): \(.value)"' parity.json >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Comment on PR
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            let body = '## 🔍 Parity Check Results\n\n';
            
            try {
              const report = JSON.parse(fs.readFileSync('services/api/parity.json', 'utf8'));
              const summary = report.summary;
              
              body += `- **Total Checked**: ${summary.total_checked}\n`;
              body += `- **Mismatches**: ${summary.total_mismatches}\n`;
              body += `- **Mismatch Rate**: ${summary.mismatch_percentage}%\n\n`;
              
              if (summary.total_mismatches > 0) {
                body += '### ⚠️ Mismatches by Field:\n';
                for (const [field, count] of Object.entries(summary.by_field)) {
                  if (count > 0) {
                    body += `- **${field}**: ${count}\n`;
                  }
                }
                body += '\n📄 Download artifacts for detailed report.';
              } else {
                body += '### ✅ No mismatches detected!';
              }
            } catch (error) {
              body += '⚠️ Could not parse parity report.\n';
              body += `Error: ${error.message}`;
            }
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });
      
      - name: Fail if parity check failed
        if: steps.parity.outcome == 'failure' && github.ref == 'refs/heads/main'
        run: |
          echo "::error::Parity check failed on main branch"
          exit 1

  # ===================================================================
  # INTEGRATION TESTS
  # ===================================================================
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [unit-tests]
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: applylens_test
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      
      elasticsearch:
        image: docker.elastic.co/elasticsearch/elasticsearch:8.12.0
        env:
          discovery.type: single-node
          xpack.security.enabled: false
          ES_JAVA_OPTS: -Xms512m -Xmx512m
        ports:
          - 9200:9200
        options: >-
          --health-cmd "curl -f http://localhost:9200/_cluster/health || exit 1"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        working-directory: services/api
        run: |
          pip install -e .[test]
      
      - name: Run database migrations
        working-directory: services/api
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/applylens_test
        run: |
          alembic upgrade head
      
      - name: Run integration tests
        working-directory: services/api
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/applylens_test
          ELASTICSEARCH_URL: http://localhost:9200
          ES_INDEX: test_emails
        run: |
          pytest -m integration \
            --junit-xml=integration-test-results.xml \
            -v
      
      - name: Upload integration test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-results
          path: services/api/integration-test-results.xml
